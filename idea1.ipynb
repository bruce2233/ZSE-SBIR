{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from options import Option\n",
    "from data_utils.dataset import load_data_test\n",
    "from model.model import Model\n",
    "from utils.util import setup_seed, load_checkpoint\n",
    "import torchvision\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test args: Namespace(data_path='./datasets', dataset='sketchy_extend', test_class='test_class_sketchy25', cls_number=100, d_model=768, d_ff=1024, head=8, number=1, pretrained=True, anchor_number=49, save='./checkpoints/sketchy_ext', batch=2, epoch=30, datasetLen=10000, learning_rate=1e-05, weight_decay=0.01, load='./checkpoint/sketchy_ext/best_checkpoint.pth', retrieval='rn', testall=False, test_sk=20, test_im=20, num_workers=4, choose_cuda='0', seed=2021)\n"
     ]
    }
   ],
   "source": [
    "args = Option().parse()\n",
    "args.load = \"./checkpoint/sketchy_ext/best_checkpoint.pth\"\n",
    "args.batch = 2\n",
    "\n",
    "print(\"test args:\", str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.ap import calculate\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current cuda: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.choose_cuda\n",
    "print(\"current cuda: \" + args.choose_cuda)\n",
    "setup_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used for valid or test sketch / image:\n",
      "(77,) (1711,)\n",
      "used for train sketch / image:\n",
      "(55252,) (68401,)\n",
      "=> loading model './checkpoint/sketchy_ext/best_checkpoint.pth'\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "sk_valid_data, im_valid_data = load_data_test(args)\n",
    "\n",
    "# prepare model\n",
    "model = Model(args)\n",
    "model = model.half()\n",
    "\n",
    "if args.load is not None:\n",
    "    checkpoint = load_checkpoint(args.load)\n",
    "\n",
    "cur = model.state_dict()\n",
    "new = {k: v for k, v in checkpoint['model'].items() if k in cur.keys()}\n",
    "cur.update(new)\n",
    "model.load_state_dict(cur)\n",
    "\n",
    "if len(args.choose_cuda) > 1:\n",
    "    model = torch.nn.parallel.DataParallel(model.to('cuda'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image data\n",
      "loading sketch data\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print('loading image data')\n",
    "sk_dataload = DataLoader(sk_valid_data, batch_size=args.test_sk, num_workers=args.num_workers, drop_last=False)\n",
    "print('loading sketch data')\n",
    "im_dataload = DataLoader(im_valid_data, batch_size=args.test_im, num_workers=args.num_workers, drop_last=False)\n",
    "\n",
    "dist_im = None\n",
    "all_dist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (sk, sk_label) in enumerate(tqdm(sk_dataload)):\n",
    "        #sk.shape=(20,3,224,224)\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            all_sk_label = sk_label.numpy()\n",
    "        else:\n",
    "            all_sk_label = np.concatenate((all_sk_label, sk_label.numpy()), axis=0)\n",
    "\n",
    "        sk_len = sk.size(0)\n",
    "        sk = sk.cuda()\n",
    "        #debug\n",
    "        print(sk[0].shape)\n",
    "        # cv2.imwrite(f\"./output/sk-{i}\",sk[0].cpu().numpy())\n",
    "        if i==0:\n",
    "            grid_sk = torchvision.utils.make_grid(sk)\n",
    "            torchvision.utils.save_image(grid_sk,f\"./output/sk.jpg\")\n",
    "        \n",
    "        sk, sk_idxs = model(sk, None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "        for j, (im, im_label) in enumerate(tqdm(im_dataload)):\n",
    "            if i == 0 and j == 0:\n",
    "                all_im_label = im_label.numpy()\n",
    "            elif i == 0 and j > 0:\n",
    "                all_im_label = np.concatenate((all_im_label, im_label.numpy()), axis=0)\n",
    "\n",
    "            im_len = im.size(0)\n",
    "            im = im.cuda()\n",
    "            im, im_idxs = model(im, None, 'test', only_sa=True)\n",
    "\n",
    "            sk_temp = sk.unsqueeze(1).repeat(1, im_len, 1, 1).flatten(0, 1).cuda() #(400,197,768) #?difference\n",
    "            im_temp = im.unsqueeze(0).repeat(sk_len, 1, 1, 1).flatten(0, 1).cuda() #(400,197,768)\n",
    "            \n",
    "            if args.retrieval == 'rn':\n",
    "                feature_1, feature_2 = model(sk_temp, im_temp, 'test')\n",
    "            #? when retrieval == 'sa'\n",
    "            if args.retrieval == 'sa':\n",
    "                feature_1, feature_2 = torch.cat((sk_temp[:, 0], im_temp[:, 0]), dim=0), None\n",
    "\n",
    "            # print(feature_1.size())    # [2*sk*im, 768] #2 means sk and im cls\n",
    "            # print(feature_2.size())    # [sk*im, 1]\n",
    "\n",
    "            if args.retrieval == 'rn':\n",
    "                if j == 0:\n",
    "                    dist_im = - feature_2.view(sk_len, im_len).cpu().data.numpy()  # 1*args.batch\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, - feature_2.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "            if args.retrieval == 'sa':\n",
    "                dist_temp = F.pairwise_distance(F.normalize(feature_1[:sk_len * im_len]),\n",
    "                                                F.normalize(feature_1[sk_len * im_len:]), 2)\n",
    "                if j == 0:\n",
    "                    dist_im = dist_temp.view(sk_len, im_len).cpu().data.numpy()\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, dist_temp.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "\n",
    "        if i == 0:\n",
    "            all_dist = dist_im\n",
    "        else:\n",
    "            all_dist = np.concatenate((all_dist, dist_im), axis=0)\n",
    "        print(all_dist.shape)\n",
    "        #all_dist.shape=(all_sk_label.size, all_im_label.size)\n",
    "    # print(all_sk_label.size, all_im_label.size)     # [762 x 1711] / 2\n",
    "class_same = (np.expand_dims(all_sk_label, axis=1) == np.expand_dims(all_im_label, axis=0)) * 1\n",
    "# print(all_dist.size, class_same.size)     # [762 x 1711] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 1711)\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(class_same.shape)\n",
    "print(class_same)\n",
    "np.savetxt(\"./output/all_dist\",all_dist)\n",
    "np.savetxt(\"./output/class_same\",class_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval time: 0.5573358535766602\n",
      "0.680195628754997 0.6593741691830883 0.6408593850189362 0.6408593850189362\n"
     ]
    }
   ],
   "source": [
    "map_all, map_200, precision100, precision200 = calculate(all_dist, class_same, test=True)\n",
    "print(map_all,map_200,precision100,precision200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 1711)\n",
      "[[ 286  254  302 ...  173 1272  179]\n",
      " [ 382  302  271 ...  342  349  347]\n",
      " [ 253  302  255 ...  349  228  179]\n",
      " ...\n",
      " [ 160 1244 1213 ...  582 1366  604]\n",
      " [1411 1455 1421 ...  337 1213  567]\n",
      " [ 266  971  247 ... 1304  928  819]]\n"
     ]
    }
   ],
   "source": [
    "arg_sort_sim = all_dist.argsort()   # 得到从小到大索引值\n",
    "print(arg_sort_sim.shape)\n",
    "print(arg_sort_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_replace_data(sk_index, im_index):\n",
    "    '''\n",
    "    sk_index: 0\n",
    "    im_index: list\n",
    "    '''\n",
    "    (sk,_) = sk_valid_data[sk_index]\n",
    "    sk = torch.unsqueeze(sk,0)\n",
    "    \n",
    "    for i,v in enumerate(im_index):\n",
    "        if i == 0:    \n",
    "            (im,_) = im_valid_data[im_index[0]]\n",
    "            im = torch.unsqueeze(im,0)\n",
    "        else:    \n",
    "            im = torch.cat((im,im_valid_data[v][0].unsqueeze(0)))\n",
    "    \n",
    "    return sk,im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 228, 680])\n"
     ]
    }
   ],
   "source": [
    "sk_index=0\n",
    "im_index = [286,254,302]\n",
    "(sk_tmp, im_tmp) = patch_replace_data(sk_index,im_index)\n",
    "print(sk_tmp.shape, im_tmp.shape)\n",
    "\n",
    "torchvision.utils.save_image(sk_tmp.cuda(),f\"./output/sk-{sk_index}.jpg\")\n",
    "\n",
    "im_tmp = torchvision.utils.make_grid(im_tmp)\n",
    "torchvision.utils.save_image(im_tmp.cuda(),f\"./output/im_top_{len(im_index)}.jpg\")\n",
    "print(sk_tmp.shape, im_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 3, 224, 224])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "from model import rn\n",
    "\n",
    "sk, im = patch_replace_data(sk_index, im_index)\n",
    "print(sk.shape, im.shape)\n",
    "\n",
    "\n",
    "sk_sa, sk_idxs = model(sk.cuda(), None, 'test', only_sa=True)#sk_sa.shape=(20,192,768)\n",
    "im_sa, im_idxs = model(im.cuda(), None, 'test', only_sa=True)#im_sa.shape=(20,192,768)\n",
    "\n",
    "\n",
    "sk_im_sa = torch.cat((sk_sa, im_sa), dim=0)\n",
    "ca_fea = model.ca(sk_im_sa)  # [2b, 197, 768]\n",
    "cls_fea = ca_fea[:, 0]  # [2b, 1, 768]\n",
    "token_fea = ca_fea[:, 1:]  # [2b, 196, 768]\n",
    "batch = token_fea.size(0)\n",
    "\n",
    "print(token_fea.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196, 768]) torch.Size([2, 196, 768])\n",
      "torch.Size([2, 196, 196])\n"
     ]
    }
   ],
   "source": [
    "# token_fea = einops.rearrange(token_fea,\"b d h w -> b d (h w)\") #token_fea = token_fea.view(batch, 768, 14, 14)\n",
    "sk_fea = token_fea[0]\n",
    "im_fea = token_fea[sk.size(0):]\n",
    "# np.savetxt(\"./output/sk_fea\", sk_fea.cpu())\n",
    "# np.savetxt(\"./output/im_fea\", im_fea.cpu())\n",
    "print(sk_fea.shape, im_fea.shape)\n",
    "cos_scores = rn.cos_similar(sk_fea, im_fea)\n",
    "print(cos_scores.shape)\n",
    "np.savetxt(\"./output/cos_scores\",cos_scores.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(sk.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cos_scores.argsort(0).shape,cos_scores.argsort(0))\n",
    "# print(torch.argmax(einops.rearrange(cos_scores,\"a b c -> b (a c)\")))\n",
    "b = einops.rearrange(cos_scores,\"a b c -> b (a c)\")\n",
    "# print(cos_scores.shape,cos_scores)\n",
    "\n",
    "max_indices = torch.empty((0,2), dtype=int)\n",
    "print(b)\n",
    "print(max_indices)\n",
    "\n",
    "for i in b:\n",
    "    max_indices_item = torch.argmax(i)\n",
    "    print(i.shape)\n",
    "    new = np.unravel_index(max_indices_item.cpu(),(cos_scores.shape[0],cos_scores.shape[2]))\n",
    "    # print(torch.Tensor(new))\n",
    "    max_indices = torch.cat((max_indices, torch.tensor(new, dtype=torch.int).unsqueeze(0)), 0)\n",
    "    print(max_indices)\n",
    "    \n",
    "# print(np.unravel_index(b.values, (3, 196)))\n",
    "np.savetxt(\"./output/max_indices\",max_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = max_indices\n",
    "\n",
    "print(im.shape)\n",
    "# x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "x = torch.zeros((0, 3, 14,14))\n",
    "print(x)\n",
    "for i in indices:\n",
    "    patch_index = np.unravel_index(i[1],(16,16))\n",
    "    item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], int(im.shape[-1]/16))\n",
    "    print(item.shape)\n",
    "    x= torch.cat([x, item.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torchvision.utils.make_grid(x,nrow=16)\n",
    "torchvision.utils.save_image(x,\"./output/patch_replace.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_match(im, indices):\n",
    "    '''\n",
    "        im: (b,c,w,h)\n",
    "        indices: (m,im.shape.len)\n",
    "    '''\n",
    "    print(im.shape)\n",
    "    x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "    print(x)\n",
    "    for i in indices:\n",
    "        patch_index = np.unravel_index(i[1],(16,16))\n",
    "        item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], im.shape[-1]/16)\n",
    "        x= torch.cat([x, item])\n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch2im(patch_index,im, patch_size):\n",
    "    '''\n",
    "    im: (c, w, h)\n",
    "    patch_index: (2)\n",
    "    return: (c, patch_size, patch_size)\n",
    "    '''\n",
    "    print(patch_index.shape, im.shape, patch_size)\n",
    "    # width_range = torch.tensor([patch_index[0]*patch_size,(patch_index[0]+1)*patch_size],dtype=int)\n",
    "    # height_range = torch.tensor([patch_index[1]*patch_size,(patch_index[1]+1)*patch_size],dtype=int)\n",
    "    print(patch_index)\n",
    "    print(patch_index[0].item()*patch_size)\n",
    "        \n",
    "    return im[:, \\\n",
    "        patch_index[0]*patch_size:(patch_index[0].item()+1)*patch_size, \\\n",
    "        patch_index[1].item()*patch_size:(patch_index[1].item()+1)*patch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # [2b, n, n] n=patches**2\n",
    "cos_scores = cos_scores.view(batch // 2, -1)\n",
    "\n",
    "rn.cos_similar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_dataload[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "# map_all, map_200, precision_100, precision_200 = valid_cls(args, model, sk_valid_data, im_valid_data)\n",
    "print(f'map_all:{map_all:.4f} map_200:{map_200:.4f} precision_100:{precision100:.4f} precision_200:{precision200:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4818a0b8c316263be072c2082609790d2bac6bbfe2378382b84905edb944ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
