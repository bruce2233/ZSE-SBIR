{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from options import Option\n",
    "from data_utils.dataset import load_data_test\n",
    "from model.model import Model\n",
    "from utils.util import setup_seed, load_checkpoint\n",
    "import torchvision\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test args: Namespace(data_path='./datasets', dataset='sketchy_extend', test_class='test_class_sketchy25', cls_number=100, d_model=768, d_ff=1024, head=8, number=1, pretrained=True, anchor_number=49, save='./checkpoints/sketchy_ext', batch=2, epoch=30, datasetLen=10000, learning_rate=1e-05, weight_decay=0.01, load='./checkpoint/sketchy_ext/best_checkpoint.pth', retrieval='rn', testall=False, test_sk=20, test_im=20, num_workers=4, choose_cuda='0', seed=2021)\n"
     ]
    }
   ],
   "source": [
    "args = Option().parse()\n",
    "args.load = \"./checkpoint/sketchy_ext/best_checkpoint.pth\"\n",
    "args.batch = 2\n",
    "\n",
    "print(\"test args:\", str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.ap import calculate\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current cuda: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.choose_cuda\n",
    "print(\"current cuda: \" + args.choose_cuda)\n",
    "setup_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used for valid or test sketch / image:\n",
      "(77,) (1711,)\n",
      "used for train sketch / image:\n",
      "(55252,) (68401,)\n",
      "=> loading model './checkpoint/sketchy_ext/best_checkpoint.pth'\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "sk_valid_data, im_valid_data = load_data_test(args)\n",
    "\n",
    "# prepare model\n",
    "model = Model(args)\n",
    "model = model.half()\n",
    "\n",
    "if args.load is not None:\n",
    "    checkpoint = load_checkpoint(args.load)\n",
    "\n",
    "cur = model.state_dict()\n",
    "new = {k: v for k, v in checkpoint['model'].items() if k in cur.keys()}\n",
    "cur.update(new)\n",
    "model.load_state_dict(cur)\n",
    "\n",
    "if len(args.choose_cuda) > 1:\n",
    "    model = torch.nn.parallel.DataParallel(model.to('cuda'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image data\n",
      "loading sketch data\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print('loading image data')\n",
    "sk_dataload = DataLoader(sk_valid_data, batch_size=args.test_sk, num_workers=args.num_workers, drop_last=False)\n",
    "print('loading sketch data')\n",
    "im_dataload = DataLoader(im_valid_data, batch_size=args.test_im, num_workers=args.num_workers, drop_last=False)\n",
    "\n",
    "dist_im = None\n",
    "all_dist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:08<00:00, 10.74it/s]\n",
      " 25%|██▌       | 1/4 [00:10<00:32, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1711)\n",
      "1\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:07<00:00, 11.01it/s]\n",
      " 50%|█████     | 2/4 [00:18<00:18,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1711)\n",
      "2\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:07<00:00, 10.97it/s]\n",
      " 75%|███████▌  | 3/4 [00:26<00:08,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1711)\n",
      "3\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:06<00:00, 12.32it/s]\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 1711)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (sk, sk_label) in enumerate(tqdm(sk_dataload)):\n",
    "        #sk.shape=(20,3,224,224)\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            all_sk_label = sk_label.numpy()\n",
    "        else:\n",
    "            all_sk_label = np.concatenate((all_sk_label, sk_label.numpy()), axis=0)\n",
    "\n",
    "        sk_len = sk.size(0)\n",
    "        sk = sk.cuda()\n",
    "        #debug\n",
    "        print(sk[0].shape)\n",
    "        # cv2.imwrite(f\"./output/sk-{i}\",sk[0].cpu().numpy())\n",
    "        if i==0:\n",
    "            grid_sk = torchvision.utils.make_grid(sk)\n",
    "            torchvision.utils.save_image(grid_sk,f\"./output/sk.jpg\")\n",
    "        \n",
    "        sk, sk_idxs = model(sk, None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "        for j, (im, im_label) in enumerate(tqdm(im_dataload)):\n",
    "            if i == 0 and j == 0:\n",
    "                all_im_label = im_label.numpy()\n",
    "            elif i == 0 and j > 0:\n",
    "                all_im_label = np.concatenate((all_im_label, im_label.numpy()), axis=0)\n",
    "\n",
    "            im_len = im.size(0)\n",
    "            im = im.cuda()\n",
    "            im, im_idxs = model(im, None, 'test', only_sa=True)\n",
    "\n",
    "            sk_temp = sk.unsqueeze(1).repeat(1, im_len, 1, 1).flatten(0, 1).cuda() #(400,197,768) #?difference\n",
    "            im_temp = im.unsqueeze(0).repeat(sk_len, 1, 1, 1).flatten(0, 1).cuda() #(400,197,768)\n",
    "            \n",
    "            if args.retrieval == 'rn':\n",
    "                feature_1, feature_2 = model(sk_temp, im_temp, 'test')\n",
    "            #? when retrieval == 'sa'\n",
    "            if args.retrieval == 'sa':\n",
    "                feature_1, feature_2 = torch.cat((sk_temp[:, 0], im_temp[:, 0]), dim=0), None\n",
    "\n",
    "            # print(feature_1.size())    # [2*sk*im, 768] #2 means sk and im cls\n",
    "            # print(feature_2.size())    # [sk*im, 1]\n",
    "\n",
    "            if args.retrieval == 'rn':\n",
    "                if j == 0:\n",
    "                    dist_im = - feature_2.view(sk_len, im_len).cpu().data.numpy()  # 1*args.batch\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, - feature_2.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "            if args.retrieval == 'sa':\n",
    "                dist_temp = F.pairwise_distance(F.normalize(feature_1[:sk_len * im_len]),\n",
    "                                                F.normalize(feature_1[sk_len * im_len:]), 2)\n",
    "                if j == 0:\n",
    "                    dist_im = dist_temp.view(sk_len, im_len).cpu().data.numpy()\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, dist_temp.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "\n",
    "        if i == 0:\n",
    "            all_dist = dist_im\n",
    "        else:\n",
    "            all_dist = np.concatenate((all_dist, dist_im), axis=0)\n",
    "        print(all_dist.shape)\n",
    "        #all_dist.shape=(all_sk_label.size, all_im_label.size)\n",
    "    # print(all_sk_label.size, all_im_label.size)     # [762 x 1711] / 2\n",
    "class_same = (np.expand_dims(all_sk_label, axis=1) == np.expand_dims(all_im_label, axis=0)) * 1\n",
    "# print(all_dist.size, class_same.size)     # [762 x 1711] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 1711)\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(class_same.shape)\n",
    "print(class_same)\n",
    "np.savetxt(\"./output/all_dist\",all_dist)\n",
    "np.savetxt(\"./output/class_same\",class_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval time: 0.5300471782684326\n",
      "0.680195628754997 0.6593741691830883 0.6408593850189362 0.6408593850189362\n"
     ]
    }
   ],
   "source": [
    "map_all, map_200, precision100, precision200 = calculate(all_dist, class_same, test=True)\n",
    "print(map_all,map_200,precision100,precision200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 1711)\n",
      "[[ 286  254  302 ...  173 1272  179]\n",
      " [ 382  302  271 ...  342  349  347]\n",
      " [ 253  302  255 ...  349  228  179]\n",
      " ...\n",
      " [ 160 1244 1213 ...  582 1366  604]\n",
      " [1411 1455 1421 ...  337 1213  567]\n",
      " [ 266  971  247 ... 1304  928  819]]\n"
     ]
    }
   ],
   "source": [
    "arg_sort_sim = all_dist.argsort()   # 得到从小到大索引值\n",
    "print(arg_sort_sim.shape)\n",
    "print(arg_sort_sim)\n",
    "np.savetxt(\"./output/arg_sort_sim\",torch.tensor(arg_sort_sim,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_replace_data(sk_index, im_index):\n",
    "    '''\n",
    "    sk_index: 0\n",
    "    im_index: list\n",
    "    '''\n",
    "    (sk,_) = sk_valid_data[sk_index]\n",
    "    sk = torch.unsqueeze(sk,0)\n",
    "    \n",
    "    for i,v in enumerate(im_index):\n",
    "        if i == 0:    \n",
    "            (im,_) = im_valid_data[im_index[0]]\n",
    "            im = torch.unsqueeze(im,0)\n",
    "        else:    \n",
    "            im = torch.cat((im,im_valid_data[v][0].unsqueeze(0)))\n",
    "    \n",
    "    return sk,im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 228, 680])\n"
     ]
    }
   ],
   "source": [
    "sk_index=0\n",
    "im_index = [286 , 254 , 302]\n",
    "(sk_tmp, im_tmp) = patch_replace_data(sk_index,im_index)\n",
    "print(sk_tmp.shape, im_tmp.shape)\n",
    "\n",
    "torchvision.utils.save_image(sk_tmp.cuda(),f\"./output/sk-{sk_index}.jpg\")\n",
    "\n",
    "im_tmp = torchvision.utils.make_grid(im_tmp)\n",
    "torchvision.utils.save_image(im_tmp.cuda(),f\"./output/im_top_{len(im_index)}.jpg\")\n",
    "print(sk_tmp.shape, im_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([3, 3, 224, 224])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "from model import rn\n",
    "\n",
    "sk, im = patch_replace_data(sk_index, im_index)\n",
    "print(sk.shape, im.shape)\n",
    "\n",
    "\n",
    "sk_sa, sk_idxs = model(sk.cuda(), None, 'test', only_sa=True)#sk_sa.shape=(20,192,768)\n",
    "im_sa, im_idxs = model(im.cuda(), None, 'test', only_sa=True)#im_sa.shape=(20,192,768)\n",
    "\n",
    "\n",
    "sk_im_sa = torch.cat((sk_sa, im_sa), dim=0)\n",
    "ca_fea = model.ca(sk_im_sa)  # [2b, 197, 768]\n",
    "cls_fea = ca_fea[:, 0]  # [2b, 1, 768]\n",
    "token_fea = ca_fea[:, 1:]  # [2b, 196, 768]\n",
    "batch = token_fea.size(0)\n",
    "\n",
    "print(token_fea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196, 768]) torch.Size([3, 196, 768])\n",
      "torch.Size([3, 196, 196])\n"
     ]
    }
   ],
   "source": [
    "# token_fea = einops.rearrange(token_fea,\"b d h w -> b d (h w)\") #token_fea = token_fea.view(batch, 768, 14, 14)\n",
    "sk_fea = token_fea[0]\n",
    "im_fea = token_fea[sk.size(0):]\n",
    "# np.savetxt(\"./output/sk_fea\", sk_fea.cpu())\n",
    "# np.savetxt(\"./output/im_fea\", im_fea.cpu())\n",
    "print(sk_fea.shape, im_fea.shape)\n",
    "cos_scores = rn.cos_similar(sk_fea, im_fea)\n",
    "print(cos_scores.shape)\n",
    "np.savetxt(\"./output/cos_scores\",cos_scores.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8413, 0.8198, 0.8320,  ..., 0.6865, 0.6904, 0.6870],\n",
      "        [0.8403, 0.8306, 0.8423,  ..., 0.6860, 0.6885, 0.6831],\n",
      "        [0.8345, 0.8306, 0.8447,  ..., 0.6841, 0.6855, 0.6772],\n",
      "        ...,\n",
      "        [0.8340, 0.8271, 0.8389,  ..., 0.6875, 0.6870, 0.6826],\n",
      "        [0.8350, 0.8218, 0.8345,  ..., 0.6914, 0.6934, 0.6899],\n",
      "        [0.8359, 0.8115, 0.8247,  ..., 0.6899, 0.6929, 0.6948]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "tensor([], size=(0, 2), dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# print(cos_scores.argsort(0).shape,cos_scores.argsort(0))\n",
    "# print(torch.argmax(einops.rearrange(cos_scores,\"a b c -> b (a c)\")))\n",
    "b = einops.rearrange(cos_scores,\"a b c -> b (a c)\")\n",
    "# print(cos_scores.shape,cos_scores)\n",
    "\n",
    "max_indices = torch.empty((0,2), dtype=int)\n",
    "print(b)\n",
    "print(max_indices)\n",
    "\n",
    "for i in b:\n",
    "    max_indices_item = torch.argmax(i)\n",
    "    # print(i.shape)\n",
    "    new = np.unravel_index(max_indices_item.cpu(),(cos_scores.shape[0],cos_scores.shape[2]))\n",
    "    # print(torch.Tensor(new))\n",
    "    max_indices = torch.cat((max_indices, torch.tensor(new, dtype=torch.int).unsqueeze(0)), 0)\n",
    "    # print(max_indices)\n",
    "    \n",
    "# print(np.unravel_index(b.values, (3, 196)))\n",
    "np.savetxt(\"./output/max_indices\",max_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch2im(patch_index,im, patch_size):\n",
    "    '''\n",
    "    im: (c, w, h)\n",
    "    patch_index: (2)\n",
    "    return: (c, patch_size, patch_size)\n",
    "    '''\n",
    "    # print(patch_index.shape, im.shape, patch_size)\n",
    "    # print(patch_index)\n",
    "    # print(patch_index[0].item()*patch_size)\n",
    "        \n",
    "    return im[:, \\\n",
    "        patch_index[0]*patch_size:(patch_index[0].item()+1)*patch_size, \\\n",
    "        patch_index[1].item()*patch_size:(patch_index[1].item()+1)*patch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_match(im, indices,patch_size):\n",
    "    '''\n",
    "        im: (b,c,w,h)\n",
    "        indices: (m,im.shape.len)\n",
    "    '''\n",
    "    # print(im.shape)\n",
    "    x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "    # print(x)\n",
    "    for i in indices:\n",
    "        patch_index = np.unravel_index(i[1],(im.size(-1)/patch_size,im.size(-1)/patch_size))\n",
    "        item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], patch_size)\n",
    "        x= torch.cat([x, item])\n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch replace op test\n",
    "# indices = max_indices\n",
    "\n",
    "# print(im.shape)\n",
    "# # x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "# x = torch.zeros((0, 3, 14,14))\n",
    "# # print(x)\n",
    "# for i,v in enumerate(indices):\n",
    "#     patch_index = np.unravel_index(i,(16,16))\n",
    "#     item = patch2im(torch.tensor(patch_index,dtype=int), im[0], im.shape[-1]//16)\n",
    "#     # print(item.shape)\n",
    "#     x= torch.cat([x, item.unsqueeze(0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "indices = max_indices\n",
    "\n",
    "print(im.shape)\n",
    "# x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "x = torch.zeros((0, 3, 16,16))\n",
    "# print(x)\n",
    "for i in indices:\n",
    "    patch_index = np.unravel_index(i[1],(14,14))\n",
    "    item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], int(im.shape[-1]/14))\n",
    "    # print(item.shape)\n",
    "    x= torch.cat([x, item.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torchvision.utils.make_grid(x,nrow=14)\n",
    "torchvision.utils.save_image(x,\"./output/patch_replace.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 254, 254]) tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.1059,  ...,  0.1843,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.1294,  ..., -0.0510,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.3882,  ..., -0.3569,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.5059,  ..., -0.4980,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.8115,  ..., -0.8198,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.8823,  ..., -0.9136,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_all:0.6802 map_200:0.6594 precision_100:0.6409 precision_200:0.6409\n"
     ]
    }
   ],
   "source": [
    "# valid\n",
    "# map_all, map_200, precision_100, precision_200 = valid_cls(args, model, sk_valid_data, im_valid_data)\n",
    "print(f'map_all:{map_all:.4f} map_200:{map_200:.4f} precision_100:{precision100:.4f} precision_200:{precision200:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqgan_dict = torch.load(\"../download/last.ckpt\")\n",
    "print(vqgan_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append(\"./vqgan_pytorch/\")\n",
    "\n",
    "import vqgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"VQGAN\")\n",
    "parser.add_argument('--latent-dim', type=int, default=256, help='Latent dimension n_z (default: 256)')\n",
    "parser.add_argument('--image-size', type=int, default=256, help='Image height and width (default: 256)')\n",
    "parser.add_argument('--num-codebook-vectors', type=int, default=1024, help='Number of codebook vectors (default: 256)')\n",
    "parser.add_argument('--beta', type=float, default=0.25, help='Commitment loss scalar (default: 0.25)')\n",
    "parser.add_argument('--image-channels', type=int, default=3, help='Number of channels of images (default: 3)')\n",
    "parser.add_argument('--dataset-path', type=str, default='/data', help='Path to data (default: /data)')\n",
    "parser.add_argument('--device', type=str, default=\"cuda\", help='Which device the training is on')\n",
    "parser.add_argument('--batch-size', type=int, default=6, help='Input batch size for training (default: 6)')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='Number of epochs to train (default: 50)')\n",
    "parser.add_argument('--learning-rate', type=float, default=2.25e-05, help='Learning rate (default: 0.0002)')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='Adam beta param (default: 0.0)')\n",
    "parser.add_argument('--beta2', type=float, default=0.9, help='Adam beta param (default: 0.999)')\n",
    "parser.add_argument('--disc-start', type=int, default=10000, help='When to start the discriminator (default: 0)')\n",
    "parser.add_argument('--disc-factor', type=float, default=1., help='')\n",
    "parser.add_argument('--rec-loss-factor', type=float, default=1., help='Weighting factor for reconstruction loss.')\n",
    "parser.add_argument('--perceptual-loss-factor', type=float, default=1., help='Weighting factor for perceptual loss.')\n",
    "\n",
    "args2 = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQGAN(\n",
      "  (encoder): Encoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (3): DownSampleBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (4): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): DownSampleBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (7): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (channel_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (8): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (9): DownSampleBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (10): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (11): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (12): DownSampleBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "      (13): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (channel_up): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (14): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (15): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (16): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (17): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (18): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (19): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (20): GroupNorm(\n",
      "        (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      )\n",
      "      (21): Swish()\n",
      "      (22): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (6): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (8): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (9): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (10): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (channel_up): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (11): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (12): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (13): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (14): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (15): NonLocalBlock(\n",
      "        (gn): GroupNorm(\n",
      "          (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        )\n",
      "        (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (16): UpSampleBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (17): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (18): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (19): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (20): UpSampleBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (21): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (channel_up): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (22): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (23): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (24): UpSampleBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (25): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (26): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (27): ResidualBlock(\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (1): Swish()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): GroupNorm(\n",
      "            (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          )\n",
      "          (4): Swish()\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (28): UpSampleBlock(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (29): GroupNorm(\n",
      "        (gn): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "      )\n",
      "      (30): Swish()\n",
      "      (31): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (codebook): Codebook(\n",
      "    (embedding): Embedding(1024, 256)\n",
      "  )\n",
      "  (quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (post_quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vqgan_model \u001b[39m=\u001b[39m vqgan\u001b[39m.\u001b[39mVQGAN(args2)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(vqgan_model)\n\u001b[0;32m----> 3\u001b[0m vqgan_model\u001b[39m.\u001b[39mload_state_dict(vqgan_dict\u001b[39m.\u001b[39;49mstate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "vqgan_model = vqgan.VQGAN(args2)\n",
    "print(vqgan_model)\n",
    "vqgan_model.load_state_dict(vqgan_dict[state_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vqgan_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(vqgan_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vqgan_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(vqgan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (sa): Self_Attention(\n",
      "    (model): ViTPatch(\n",
      "      (embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (scale): Scale_Embedding(\n",
      "        (seq): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(256, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (transformer): Encoder(\n",
      "        (encoder_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (layers): ModuleList(\n",
      "          (0-11): 12 x ModuleList(\n",
      "            (0): Encoder1DBlock(\n",
      "              (layer_norm_input): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (layer_norm_out): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): MultiHeadDotProductAttention(\n",
      "                (to_qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (mlp): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU(approximate='none')\n",
      "                  (2): Dropout(p=0.1, inplace=False)\n",
      "                  (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (4): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_out_attention): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (to_cls_token): Identity()\n",
      "    )\n",
      "  )\n",
      "  (ca): Cross_Attention(\n",
      "    (encoder): Encoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0-3): 4 x Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "            (w_2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0-1): 2 x AddAndNorm(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer1): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0-3): 4 x Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "            (w_2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0-1): 2 x AddAndNorm(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer2): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0-3): 4 x Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "            (w_2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0-1): 2 x AddAndNorm(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rn): Relation_Network(\n",
      "    (rn): Sequential(\n",
      "      (0): Linear(in_features=2401, out_features=343, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=343, out_features=49, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=49, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2d): Conv2d(768, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4818a0b8c316263be072c2082609790d2bac6bbfe2378382b84905edb944ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
