{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from options import Option\n",
    "from data_utils.dataset import load_data_test\n",
    "from model.model import Model\n",
    "from utils.util import setup_seed, load_checkpoint\n",
    "import torchvision\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Option().parse()\n",
    "args.load = \"./checkpoints/sketchy_ext/best_checkpoint.pth\"\n",
    "args.batch = 2\n",
    "args.valid_shrink_sk=200\n",
    "args.valid_shrink_im=100\n",
    "\n",
    "\n",
    "print(\"test args:\", str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.ap import calculate\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.choose_cuda\n",
    "print(\"current cuda: \" + args.choose_cuda)\n",
    "setup_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "sk_valid_data, im_valid_data = load_data_test(args)\n",
    "\n",
    "# prepare model\n",
    "model = Model(args)\n",
    "model = model.half()\n",
    "\n",
    "if args.load is not None:\n",
    "    checkpoint = load_checkpoint(args.load)\n",
    "\n",
    "cur = model.state_dict()\n",
    "new = {k: v for k, v in checkpoint['model'].items() if k in cur.keys()}\n",
    "cur.update(new)\n",
    "model.load_state_dict(cur)\n",
    "\n",
    "if len(args.choose_cuda) > 1:\n",
    "    model = torch.nn.parallel.DataParallel(model.to('cuda'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print('loading image data')\n",
    "sk_dataload = DataLoader(sk_valid_data, batch_size=args.test_sk, num_workers=args.num_workers, drop_last=False)\n",
    "print('loading sketch data')\n",
    "im_dataload = DataLoader(im_valid_data, batch_size=args.test_im, num_workers=args.num_workers, drop_last=False)\n",
    "\n",
    "dist_im = None\n",
    "all_dist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (sk, sk_label) in enumerate(tqdm(sk_dataload)):\n",
    "        #sk.shape=(20,3,224,224)\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            all_sk_label = sk_label.numpy()\n",
    "        else:\n",
    "            all_sk_label = np.concatenate((all_sk_label, sk_label.numpy()), axis=0)\n",
    "\n",
    "        sk_len = sk.size(0)\n",
    "        sk = sk.cuda()\n",
    "        #debug\n",
    "        print(sk[0].shape)\n",
    "        # cv2.imwrite(f\"./logs/sk-{i}\",sk[0].cpu().numpy())\n",
    "        if i==0:\n",
    "            grid_sk = torchvision.utils.make_grid(sk)\n",
    "            torchvision.utils.save_image(grid_sk,f\"./logs/sk.jpg\")\n",
    "        \n",
    "        sk, sk_idxs = model(sk, None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "        for j, (im, im_label) in enumerate(tqdm(im_dataload)):\n",
    "            if i == 0 and j == 0:\n",
    "                all_im_label = im_label.numpy()\n",
    "            elif i == 0 and j > 0:\n",
    "                all_im_label = np.concatenate((all_im_label, im_label.numpy()), axis=0)\n",
    "\n",
    "            im_len = im.size(0)\n",
    "            im = im.cuda()\n",
    "            im, im_idxs = model(im, None, 'test', only_sa=True)\n",
    "\n",
    "            sk_temp = sk.unsqueeze(1).repeat(1, im_len, 1, 1).flatten(0, 1).cuda() #(400,197,768) #?difference\n",
    "            im_temp = im.unsqueeze(0).repeat(sk_len, 1, 1, 1).flatten(0, 1).cuda() #(400,197,768)\n",
    "            \n",
    "            if args.retrieval == 'rn':\n",
    "                feature_1, feature_2 = model(sk_temp, im_temp, 'test')\n",
    "            #? when retrieval == 'sa'\n",
    "            if args.retrieval == 'sa':\n",
    "                feature_1, feature_2 = torch.cat((sk_temp[:, 0], im_temp[:, 0]), dim=0), None\n",
    "\n",
    "            # print(feature_1.size())    # [2*sk*im, 768] #2 means sk and im cls\n",
    "            # print(feature_2.size())    # [sk*im, 1]\n",
    "\n",
    "            if args.retrieval == 'rn':\n",
    "                if j == 0:\n",
    "                    dist_im = - feature_2.view(sk_len, im_len).cpu().data.numpy()  # 1*args.batch\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, - feature_2.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "            if args.retrieval == 'sa':\n",
    "                dist_temp = F.pairwise_distance(F.normalize(feature_1[:sk_len * im_len]),\n",
    "                                                F.normalize(feature_1[sk_len * im_len:]), 2)\n",
    "                if j == 0:\n",
    "                    dist_im = dist_temp.view(sk_len, im_len).cpu().data.numpy()\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, dist_temp.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "\n",
    "        if i == 0:\n",
    "            all_dist = dist_im\n",
    "        else:\n",
    "            all_dist = np.concatenate((all_dist, dist_im), axis=0)\n",
    "        print(all_dist.shape)\n",
    "        #all_dist.shape=(all_sk_label.size, all_im_label.size)\n",
    "    # print(all_sk_label.size, all_im_label.size)     # [762 x 1711] / 2\n",
    "class_same = (np.expand_dims(all_sk_label, axis=1) == np.expand_dims(all_im_label, axis=0)) * 1\n",
    "# print(all_dist.size, class_same.size)     # [762 x 1711] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_same.shape)\n",
    "print(class_same)\n",
    "np.savetxt(\"./logs/all_dist\",all_dist)\n",
    "np.savetxt(\"./logs/class_same\",class_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_all, map_200, precision100, precision200 = calculate(all_dist, class_same, test=True)\n",
    "print(map_all,map_200,precision100,precision200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_sort_sim = all_dist.argsort()   # 得到从小到大索引值\n",
    "print(arg_sort_sim.shape)\n",
    "print(arg_sort_sim)\n",
    "np.savetxt(\"./logs/arg_sort_sim\",torch.tensor(arg_sort_sim,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch2im(patch_index,im, patch_size):\n",
    "    '''\n",
    "    im: (c, w, h)\n",
    "    patch_index: (2)\n",
    "    return: (c, patch_size, patch_size)\n",
    "    '''\n",
    "    # print(patch_index.shape, im.shape, patch_size)\n",
    "    # print(patch_index)\n",
    "    # print(patch_index[0].item()*patch_size)\n",
    "        \n",
    "    return im[:, \\\n",
    "        patch_index[0]*patch_size:(patch_index[0].item()+1)*patch_size, \\\n",
    "        patch_index[1].item()*patch_size:(patch_index[1].item()+1)*patch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_match(im, indices,patch_size):\n",
    "    '''\n",
    "        im: (b,c,w,h)\n",
    "        indices: (m,im.shape.len)\n",
    "    '''\n",
    "    # print(im.shape)\n",
    "    x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "    # print(x)\n",
    "    for i in indices:\n",
    "        patch_index = np.unravel_index(i[1],(im.size(-1)/patch_size,im.size(-1)/patch_size))\n",
    "        item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], patch_size)\n",
    "        x= torch.cat([x, item])\n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_replace_data(im_index,im):\n",
    "    '''\n",
    "    im_index: [b_i, n_i]\n",
    "    im: [b, n, ......]\n",
    "    '''\n",
    "    for i,v in enumerate(im_index):\n",
    "        if i == 0:    \n",
    "            print(v)\n",
    "            im_rtn = im[v[0]][v[1]].unsqueeze(0)\n",
    "            print(im_rtn.shape)\n",
    "        else:    \n",
    "            im_rtn = torch.cat((im_rtn,im[v[0]][v[1]].unsqueeze(0)))\n",
    "    \n",
    "    return im_rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_index= 1\n",
    "im_index = arg_sort_sim[sk_index,:3]\n",
    "# (sk_tmp, im_tmp) = patch_replace_data(max_indices, im_valid_data[im_index[0],im_index[1],im_index[2],])\n",
    "print(sk_index, im_index)\n",
    "(sk,_) = sk_valid_data[sk_index]\n",
    "sk = sk.unsqueeze(0)\n",
    "\n",
    "tmp = [im_valid_data[i] for i in im_index]\n",
    "im = [i[0].unsqueeze(0) for i in tmp]\n",
    "im = torch.concatenate(im)\n",
    "print(sk.shape, im.shape)\n",
    "\n",
    "torchvision.utils.save_image(sk.cuda(),f\"./logs/sk-{sk_index}.jpg\")\n",
    "\n",
    "im_tmp = torchvision.utils.make_grid(im)\n",
    "torchvision.utils.save_image(im_tmp.cuda(),f\"./logs/im_top_{len(im_index)}.jpg\")\n",
    "print(sk.shape, im_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import rn\n",
    "\n",
    "\n",
    "print(sk.shape, im.shape)\n",
    "\n",
    "\n",
    "sk_sa, sk_idxs = model(sk.cuda(), None, 'test', only_sa=True)#sk_sa.shape=(20,192,768)\n",
    "im_sa, im_idxs = model(im.cuda(), None, 'test', only_sa=True)#im_sa.shape=(20,192,768)\n",
    "\n",
    "\n",
    "sk_im_sa = torch.cat((sk_sa, im_sa), dim=0)\n",
    "print(sk_im_sa.shape)\n",
    "ca_fea = model.ca(sk_im_sa)  # [2b, 197, 768]\n",
    "cls_fea = ca_fea[:, 0]  # [2b, 1, 768]\n",
    "token_fea = ca_fea[:, 1:]  # [2b, 196, 768]\n",
    "print(token_fea.shape)\n",
    "\n",
    "token_fea_tmp = einops.rearrange(token_fea, \"b (h w) c -> b c h w\", h=14)\n",
    "print(token_fea_tmp.shape)\n",
    "up_fea = model.output4VQGAN(token_fea_tmp)\n",
    "print(up_fea.shape)\n",
    "up_fea = einops.rearrange(up_fea, \"b c h w -> b (h w) c\")\n",
    "print(up_fea.shape)\n",
    "\n",
    "batch = token_fea.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_fea = einops.rearrange(token_fea,\"b d h w -> b d (h w)\") #token_fea = token_fea.view(batch, 768, 14, 14)\n",
    "sk_fea = up_fea[0]\n",
    "im_fea = up_fea[sk.size(0):]\n",
    "# np.savetxt(\"./logs/sk_fea\", sk_fea.cpu())\n",
    "# np.savetxt(\"./logs/im_fea\", im_fea.cpu())\n",
    "print(sk_fea.shape, im_fea.shape)\n",
    "cos_scores = rn.cos_similar(sk_fea, im_fea)\n",
    "print(cos_scores.shape)\n",
    "np.savetxt(\"./logs/cos_scores\",cos_scores.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cos_scores.argsort(0).shape,cos_scores.argsort(0))\n",
    "# print(torch.argmax(einops.rearrange(cos_scores,\"a b c -> b (a c)\")))\n",
    "b = einops.rearrange(cos_scores,\"a b c -> b (a c)\")\n",
    "# print(cos_scores.shape,cos_scores)\n",
    "\n",
    "max_indices = torch.empty((0,2), dtype=int)\n",
    "print(b)\n",
    "print(max_indices)\n",
    "\n",
    "for i in b:\n",
    "    max_indices_item = torch.argmax(i)\n",
    "    # print(i.shape)\n",
    "    new = np.unravel_index(max_indices_item.cpu(),(cos_scores.shape[0],cos_scores.shape[2]))\n",
    "    # print(torch.Tensor(new))\n",
    "    max_indices = torch.cat((max_indices, torch.tensor(new, dtype=torch.int).unsqueeze(0)), 0)\n",
    "    # print(max_indices)\n",
    "    \n",
    "# print(np.unravel_index(b.values, (3, 196)))\n",
    "np.savetxt(\"./logs/max_indices\",max_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch replace op test\n",
    "# indices = max_indices\n",
    "\n",
    "# print(im.shape)\n",
    "# # x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "# x = torch.zeros((0, 3, 14,14))\n",
    "# # print(x)\n",
    "# for i,v in enumerate(indices):\n",
    "#     patch_index = np.unravel_index(i,(16,16))\n",
    "#     item = patch2im(torch.tensor(patch_index,dtype=int), im[0], im.shape[-1]//16)\n",
    "#     # print(item.shape)\n",
    "#     x= torch.cat([x, item.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_indices.shape,up_fea.shape)\n",
    "im_replaced = patch_replace_data(max_indices, im_fea)\n",
    "print(im_replaced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = max_indices\n",
    "\n",
    "# print(im.shape)\n",
    "# # x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "# x = torch.zeros((0, 3, 16,16))\n",
    "# # print(x)\n",
    "# for i in indices:\n",
    "#     patch_index = np.unravel_index(i[1],(14,14))\n",
    "#     item = patch2im(torch.tensor(patch_index,dtype=int), im[i[0]], int(im.shape[-1]/14))\n",
    "#     # print(item.shape)\n",
    "#     x= torch.cat([x, item.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torchvision.utils.make_grid(x,nrow=14)\n",
    "# torchvision.utils.save_image(x,\"./logs/patch_replace.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "# map_all, map_200, precision_100, precision_200 = valid_cls(args, model, sk_valid_data, im_valid_data)\n",
    "print(f'map_all:{map_all:.4f} map_200:{map_200:.4f} precision_100:{precision100:.4f} precision_200:{precision200:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vqgan_dict = torch.load(\"../download/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!proxychains git clone https://github.com/CompVis/taming-transformers\n",
    "%cd taming-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p logs/vqgan_imagenet_f16_1024/checkpoints\n",
    "!mkdir -p logs/vqgan_imagenet_f16_1024/configs\n",
    "# !wget 'https://heibox.uni-heidelberg.de/f/140747ba53464f49b476/?dl=1' -O 'logs/vqgan_imagenet_f16_1024/checkpoints/last.ckpt' \n",
    "!proxychains wget 'https://heibox.uni-heidelberg.de/f/6ecf2af6c658432c8298/?dl=1' -O 'taming-transformers/logs/vqgan_imagenet_f16_1024/configs/model.yaml' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 einops>=0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"taming-transformers/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/g/github/ZSE-SBIR'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel, GumbelVQ\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None, is_gumbel=False):\n",
    "  if is_gumbel:\n",
    "    model = GumbelVQ(**config.model.params)\n",
    "  else:\n",
    "    model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x):\n",
    "  x = 2.*x - 1.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = x.detach().cpu()\n",
    "  x = torch.clamp(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = x.permute(1,2,0).numpy()\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "def reconstruct_with_vqgan(x, model):\n",
    "  # could also use model(x) for reconstruction but use explicit encoding and decoding here\n",
    "  z, _, [_, _, indices] = model.encode(x)\n",
    "  print(f\"VQGAN --- {model.__class__.__name__}: latent shape: {z.shape[2:]}\")\n",
    "  xrec = model.decode(z)\n",
    "  return xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruce/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bruce/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "VQModel(\n",
      "  (encoder): Encoder(\n",
      "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (down): ModuleList(\n",
      "      (0-1): 2 x Module(\n",
      "        (block): ModuleList(\n",
      "          (0-1): 2 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (downsample): Downsample(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (block): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (downsample): Downsample(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (3): Module(\n",
      "        (block): ModuleList(\n",
      "          (0-1): 2 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (downsample): Downsample(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (4): Module(\n",
      "        (block): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList(\n",
      "          (0-1): 2 x AttnBlock(\n",
      "            (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): Module(\n",
      "      (block_1): ResnetBlock(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (attn_1): AttnBlock(\n",
      "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block_2): ResnetBlock(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "    (conv_out): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (conv_in): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (mid): Module(\n",
      "      (block_1): ResnetBlock(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (attn_1): AttnBlock(\n",
      "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block_2): ResnetBlock(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up): ModuleList(\n",
      "      (0): Module(\n",
      "        (block): ModuleList(\n",
      "          (0-2): 3 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "      )\n",
      "      (1): Module(\n",
      "        (block): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1-2): 2 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (upsample): Upsample(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (block): ModuleList(\n",
      "          (0-2): 3 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (upsample): Upsample(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (3): Module(\n",
      "        (block): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1-2): 2 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList()\n",
      "        (upsample): Upsample(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Module(\n",
      "        (block): ModuleList(\n",
      "          (0-2): 3 x ResnetBlock(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (attn): ModuleList(\n",
      "          (0-2): 3 x AttnBlock(\n",
      "            (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (upsample): Upsample(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (loss): VQLPIPSWithDiscriminator(\n",
      "    (perceptual_loss): LPIPS(\n",
      "      (scaling_layer): ScalingLayer()\n",
      "      (net): vgg16(\n",
      "        (slice1): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice2): Sequential(\n",
      "          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): ReLU(inplace=True)\n",
      "          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (8): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice3): Sequential(\n",
      "          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (11): ReLU(inplace=True)\n",
      "          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (13): ReLU(inplace=True)\n",
      "          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (15): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice4): Sequential(\n",
      "          (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (18): ReLU(inplace=True)\n",
      "          (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (20): ReLU(inplace=True)\n",
      "          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (22): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice5): Sequential(\n",
      "          (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (25): ReLU(inplace=True)\n",
      "          (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (27): ReLU(inplace=True)\n",
      "          (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (29): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (lin0): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (lin1): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (lin2): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (lin3): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (lin4): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (discriminator): NLayerDiscriminator(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (quantize): VectorQuantizer2(\n",
      "    (embedding): Embedding(1024, 256)\n",
      "  )\n",
      "  (quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (post_quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "config1024 = load_config(\"taming-transformers/logs/vqgan_imagenet_f16_1024/configs/model.yaml\", display=False)\n",
    "model1024 = load_vqgan(config1024, ckpt_path=\"taming-transformers/logs/vqgan_imagenet_f16_1024/checkpoints/last.ckpt\").to(DEVICE)\n",
    "\n",
    "print(model1024)\n",
    "print(model1024, file=open(\"logs/model1024_info\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'einops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# xrec  = reconstruct_with_vqgan(x, model1024)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m h \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(im_replaced\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m),\u001b[39m\"\u001b[39m\u001b[39mb (h w) c -> b c h w\u001b[39m\u001b[39m\"\u001b[39m,h\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m) \u001b[39m#(1,256,1024)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      5\u001b[0m \u001b[39m# h = h.flatten()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'einops' is not defined"
     ]
    }
   ],
   "source": [
    "# xrec  = reconstruct_with_vqgan(x, model1024)\n",
    "h = einops.rearrange(im_replaced.unsqueeze(0),\"b (h w) c -> b c h w\",h=32) #(1,256,1024)\n",
    "h = h.to(torch.float32)\n",
    "\n",
    "# h = h.flatten()\n",
    "print(h, file=open(\"./logs/h\",\"w\"))\n",
    "h = einops.rearrange(h,\"(b c h w) -> b c h w\",b=1,c=256,h=32) #(1,256,1024)\n",
    "\n",
    "print(h.shape)\n",
    "print(h.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = einops.rearrange(h, 'b c h w -> b h w c').contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 2.5300e+02,\n",
      "           2.5400e+02, 2.5500e+02],\n",
      "          [2.5600e+02, 2.5700e+02, 2.5800e+02,  ..., 5.0900e+02,\n",
      "           5.1000e+02, 5.1100e+02],\n",
      "          [5.1200e+02, 5.1300e+02, 5.1400e+02,  ..., 7.6500e+02,\n",
      "           7.6600e+02, 7.6700e+02],\n",
      "          ...,\n",
      "          [7.4240e+03, 7.4250e+03, 7.4260e+03,  ..., 7.6770e+03,\n",
      "           7.6780e+03, 7.6790e+03],\n",
      "          [7.6800e+03, 7.6810e+03, 7.6820e+03,  ..., 7.9330e+03,\n",
      "           7.9340e+03, 7.9350e+03],\n",
      "          [7.9360e+03, 7.9370e+03, 7.9380e+03,  ..., 8.1890e+03,\n",
      "           8.1900e+03, 8.1910e+03]],\n",
      "\n",
      "         [[8.1920e+03, 8.1930e+03, 8.1940e+03,  ..., 8.4450e+03,\n",
      "           8.4460e+03, 8.4470e+03],\n",
      "          [8.4480e+03, 8.4490e+03, 8.4500e+03,  ..., 8.7010e+03,\n",
      "           8.7020e+03, 8.7030e+03],\n",
      "          [8.7040e+03, 8.7050e+03, 8.7060e+03,  ..., 8.9570e+03,\n",
      "           8.9580e+03, 8.9590e+03],\n",
      "          ...,\n",
      "          [1.5616e+04, 1.5617e+04, 1.5618e+04,  ..., 1.5869e+04,\n",
      "           1.5870e+04, 1.5871e+04],\n",
      "          [1.5872e+04, 1.5873e+04, 1.5874e+04,  ..., 1.6125e+04,\n",
      "           1.6126e+04, 1.6127e+04],\n",
      "          [1.6128e+04, 1.6129e+04, 1.6130e+04,  ..., 1.6381e+04,\n",
      "           1.6382e+04, 1.6383e+04]],\n",
      "\n",
      "         [[1.6384e+04, 1.6385e+04, 1.6386e+04,  ..., 1.6637e+04,\n",
      "           1.6638e+04, 1.6639e+04],\n",
      "          [1.6640e+04, 1.6641e+04, 1.6642e+04,  ..., 1.6893e+04,\n",
      "           1.6894e+04, 1.6895e+04],\n",
      "          [1.6896e+04, 1.6897e+04, 1.6898e+04,  ..., 1.7149e+04,\n",
      "           1.7150e+04, 1.7151e+04],\n",
      "          ...,\n",
      "          [2.3808e+04, 2.3809e+04, 2.3810e+04,  ..., 2.4061e+04,\n",
      "           2.4062e+04, 2.4063e+04],\n",
      "          [2.4064e+04, 2.4065e+04, 2.4066e+04,  ..., 2.4317e+04,\n",
      "           2.4318e+04, 2.4319e+04],\n",
      "          [2.4320e+04, 2.4321e+04, 2.4322e+04,  ..., 2.4573e+04,\n",
      "           2.4574e+04, 2.4575e+04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3757e+05, 2.3757e+05, 2.3757e+05,  ..., 2.3782e+05,\n",
      "           2.3782e+05, 2.3782e+05],\n",
      "          [2.3782e+05, 2.3782e+05, 2.3783e+05,  ..., 2.3808e+05,\n",
      "           2.3808e+05, 2.3808e+05],\n",
      "          [2.3808e+05, 2.3808e+05, 2.3808e+05,  ..., 2.3833e+05,\n",
      "           2.3833e+05, 2.3834e+05],\n",
      "          ...,\n",
      "          [2.4499e+05, 2.4499e+05, 2.4499e+05,  ..., 2.4524e+05,\n",
      "           2.4525e+05, 2.4525e+05],\n",
      "          [2.4525e+05, 2.4525e+05, 2.4525e+05,  ..., 2.4550e+05,\n",
      "           2.4550e+05, 2.4550e+05],\n",
      "          [2.4550e+05, 2.4550e+05, 2.4551e+05,  ..., 2.4576e+05,\n",
      "           2.4576e+05, 2.4576e+05]],\n",
      "\n",
      "         [[2.4576e+05, 2.4576e+05, 2.4576e+05,  ..., 2.4601e+05,\n",
      "           2.4601e+05, 2.4602e+05],\n",
      "          [2.4602e+05, 2.4602e+05, 2.4602e+05,  ..., 2.4627e+05,\n",
      "           2.4627e+05, 2.4627e+05],\n",
      "          [2.4627e+05, 2.4627e+05, 2.4627e+05,  ..., 2.4652e+05,\n",
      "           2.4653e+05, 2.4653e+05],\n",
      "          ...,\n",
      "          [2.5318e+05, 2.5318e+05, 2.5319e+05,  ..., 2.5344e+05,\n",
      "           2.5344e+05, 2.5344e+05],\n",
      "          [2.5344e+05, 2.5344e+05, 2.5344e+05,  ..., 2.5369e+05,\n",
      "           2.5369e+05, 2.5370e+05],\n",
      "          [2.5370e+05, 2.5370e+05, 2.5370e+05,  ..., 2.5395e+05,\n",
      "           2.5395e+05, 2.5395e+05]],\n",
      "\n",
      "         [[2.5395e+05, 2.5395e+05, 2.5395e+05,  ..., 2.5420e+05,\n",
      "           2.5421e+05, 2.5421e+05],\n",
      "          [2.5421e+05, 2.5421e+05, 2.5421e+05,  ..., 2.5446e+05,\n",
      "           2.5446e+05, 2.5446e+05],\n",
      "          [2.5446e+05, 2.5446e+05, 2.5447e+05,  ..., 2.5472e+05,\n",
      "           2.5472e+05, 2.5472e+05],\n",
      "          ...,\n",
      "          [2.6138e+05, 2.6138e+05, 2.6138e+05,  ..., 2.6163e+05,\n",
      "           2.6163e+05, 2.6163e+05],\n",
      "          [2.6163e+05, 2.6163e+05, 2.6163e+05,  ..., 2.6188e+05,\n",
      "           2.6189e+05, 2.6189e+05],\n",
      "          [2.6189e+05, 2.6189e+05, 2.6189e+05,  ..., 2.6214e+05,\n",
      "           2.6214e+05, 2.6214e+05]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "h = torch.arange(0.,1024*256.).reshape(1,32,32,256).cuda()\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 2.5300e+02,\n",
      "           2.5400e+02, 2.5500e+02],\n",
      "          [2.5600e+02, 2.5700e+02, 2.5800e+02,  ..., 5.0900e+02,\n",
      "           5.1000e+02, 5.1100e+02],\n",
      "          [5.1200e+02, 5.1300e+02, 5.1400e+02,  ..., 7.6500e+02,\n",
      "           7.6600e+02, 7.6700e+02],\n",
      "          ...,\n",
      "          [7.4240e+03, 7.4250e+03, 7.4260e+03,  ..., 7.6770e+03,\n",
      "           7.6780e+03, 7.6790e+03],\n",
      "          [7.6800e+03, 7.6810e+03, 7.6820e+03,  ..., 7.9330e+03,\n",
      "           7.9340e+03, 7.9350e+03],\n",
      "          [7.9360e+03, 7.9370e+03, 7.9380e+03,  ..., 8.1890e+03,\n",
      "           8.1900e+03, 8.1910e+03]],\n",
      "\n",
      "         [[8.1920e+03, 8.1930e+03, 8.1940e+03,  ..., 8.4450e+03,\n",
      "           8.4460e+03, 8.4470e+03],\n",
      "          [8.4480e+03, 8.4490e+03, 8.4500e+03,  ..., 8.7010e+03,\n",
      "           8.7020e+03, 8.7030e+03],\n",
      "          [8.7040e+03, 8.7050e+03, 8.7060e+03,  ..., 8.9570e+03,\n",
      "           8.9580e+03, 8.9590e+03],\n",
      "          ...,\n",
      "          [1.5616e+04, 1.5617e+04, 1.5618e+04,  ..., 1.5869e+04,\n",
      "           1.5870e+04, 1.5871e+04],\n",
      "          [1.5872e+04, 1.5873e+04, 1.5874e+04,  ..., 1.6125e+04,\n",
      "           1.6126e+04, 1.6127e+04],\n",
      "          [1.6128e+04, 1.6129e+04, 1.6130e+04,  ..., 1.6381e+04,\n",
      "           1.6382e+04, 1.6383e+04]],\n",
      "\n",
      "         [[1.6384e+04, 1.6385e+04, 1.6386e+04,  ..., 1.6637e+04,\n",
      "           1.6638e+04, 1.6639e+04],\n",
      "          [1.6640e+04, 1.6641e+04, 1.6642e+04,  ..., 1.6893e+04,\n",
      "           1.6894e+04, 1.6895e+04],\n",
      "          [1.6896e+04, 1.6897e+04, 1.6898e+04,  ..., 1.7149e+04,\n",
      "           1.7150e+04, 1.7151e+04],\n",
      "          ...,\n",
      "          [2.3808e+04, 2.3809e+04, 2.3810e+04,  ..., 2.4061e+04,\n",
      "           2.4062e+04, 2.4063e+04],\n",
      "          [2.4064e+04, 2.4065e+04, 2.4066e+04,  ..., 2.4317e+04,\n",
      "           2.4318e+04, 2.4319e+04],\n",
      "          [2.4320e+04, 2.4321e+04, 2.4322e+04,  ..., 2.4573e+04,\n",
      "           2.4574e+04, 2.4575e+04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3757e+05, 2.3757e+05, 2.3757e+05,  ..., 2.3782e+05,\n",
      "           2.3782e+05, 2.3782e+05],\n",
      "          [2.3782e+05, 2.3782e+05, 2.3783e+05,  ..., 2.3808e+05,\n",
      "           2.3808e+05, 2.3808e+05],\n",
      "          [2.3808e+05, 2.3808e+05, 2.3808e+05,  ..., 2.3833e+05,\n",
      "           2.3833e+05, 2.3834e+05],\n",
      "          ...,\n",
      "          [2.4499e+05, 2.4499e+05, 2.4499e+05,  ..., 2.4524e+05,\n",
      "           2.4525e+05, 2.4525e+05],\n",
      "          [2.4525e+05, 2.4525e+05, 2.4525e+05,  ..., 2.4550e+05,\n",
      "           2.4550e+05, 2.4550e+05],\n",
      "          [2.4550e+05, 2.4550e+05, 2.4551e+05,  ..., 2.4576e+05,\n",
      "           2.4576e+05, 2.4576e+05]],\n",
      "\n",
      "         [[2.4576e+05, 2.4576e+05, 2.4576e+05,  ..., 2.4601e+05,\n",
      "           2.4601e+05, 2.4602e+05],\n",
      "          [2.4602e+05, 2.4602e+05, 2.4602e+05,  ..., 2.4627e+05,\n",
      "           2.4627e+05, 2.4627e+05],\n",
      "          [2.4627e+05, 2.4627e+05, 2.4627e+05,  ..., 2.4652e+05,\n",
      "           2.4653e+05, 2.4653e+05],\n",
      "          ...,\n",
      "          [2.5318e+05, 2.5318e+05, 2.5319e+05,  ..., 2.5344e+05,\n",
      "           2.5344e+05, 2.5344e+05],\n",
      "          [2.5344e+05, 2.5344e+05, 2.5344e+05,  ..., 2.5369e+05,\n",
      "           2.5369e+05, 2.5370e+05],\n",
      "          [2.5370e+05, 2.5370e+05, 2.5370e+05,  ..., 2.5395e+05,\n",
      "           2.5395e+05, 2.5395e+05]],\n",
      "\n",
      "         [[2.5395e+05, 2.5395e+05, 2.5395e+05,  ..., 2.5420e+05,\n",
      "           2.5421e+05, 2.5421e+05],\n",
      "          [2.5421e+05, 2.5421e+05, 2.5421e+05,  ..., 2.5446e+05,\n",
      "           2.5446e+05, 2.5446e+05],\n",
      "          [2.5446e+05, 2.5446e+05, 2.5447e+05,  ..., 2.5472e+05,\n",
      "           2.5472e+05, 2.5472e+05],\n",
      "          ...,\n",
      "          [2.6138e+05, 2.6138e+05, 2.6138e+05,  ..., 2.6163e+05,\n",
      "           2.6163e+05, 2.6163e+05],\n",
      "          [2.6163e+05, 2.6163e+05, 2.6163e+05,  ..., 2.6188e+05,\n",
      "           2.6189e+05, 2.6189e+05],\n",
      "          [2.6189e+05, 2.6189e+05, 2.6189e+05,  ..., 2.6214e+05,\n",
      "           2.6214e+05, 2.6214e+05]]]], device='cuda:0')\n",
      "VectorQuantizer2(\n",
      "  (embedding): Embedding(1024, 256)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "h = model1024.quantize.forward(h) #don't use same name\n",
    "print(model1024.quantize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 0.2914,  0.9260, -1.3055,  ...,  0.3967, -0.5718,  1.0182],\n",
      "          [ 0.2914,  0.9260, -1.3055,  ...,  0.3967, -0.5717,  1.0182],\n",
      "          [ 0.2914,  0.9260, -1.3055,  ..., -0.2224, -1.0343,  1.0951],\n",
      "          ...,\n",
      "          [ 0.2915,  0.9258, -1.3057,  ...,  0.3965, -0.5718,  1.0181],\n",
      "          [ 0.2915,  0.9258, -1.3057,  ...,  0.3965, -0.5718,  1.0181],\n",
      "          [ 0.2915,  0.9258, -1.3057,  ..., -0.2227, -1.0342,  1.0952]],\n",
      "\n",
      "         [[ 1.0356,  1.2827, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  1.6152,  0.8984,  1.5244],\n",
      "          ...,\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  1.6152,  0.8984,  1.5244]],\n",
      "\n",
      "         [[-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.5566,  1.2031, -0.2695],\n",
      "          ...,\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.5566,  1.2031, -0.2695]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.4062, -1.8906,  1.4688],\n",
      "          ...,\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.4062, -1.8906,  1.4688]],\n",
      "\n",
      "         [[-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.0312,  1.3438, -0.4375],\n",
      "          ...,\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.0312,  1.3438, -0.4375]],\n",
      "\n",
      "         [[ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -0.6094,  1.8594, -1.5000],\n",
      "          ...,\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -0.6094,  1.8594, -1.5000]]]],\n",
      "       device='cuda:0'), tensor(2.8633e+10, device='cuda:0', grad_fn=<AddBackward0>), (None, None, tensor([800, 800, 800,  ..., 585, 585, 585], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 0.2914,  0.9260, -1.3055,  ...,  0.3967, -0.5718,  1.0182],\n",
      "          [ 0.2914,  0.9260, -1.3055,  ...,  0.3967, -0.5717,  1.0182],\n",
      "          [ 0.2914,  0.9260, -1.3055,  ..., -0.2224, -1.0343,  1.0951],\n",
      "          ...,\n",
      "          [ 0.2915,  0.9258, -1.3057,  ...,  0.3965, -0.5718,  1.0181],\n",
      "          [ 0.2915,  0.9258, -1.3057,  ...,  0.3965, -0.5718,  1.0181],\n",
      "          [ 0.2915,  0.9258, -1.3057,  ..., -0.2227, -1.0342,  1.0952]],\n",
      "\n",
      "         [[ 1.0356,  1.2827, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  1.6152,  0.8984,  1.5244],\n",
      "          ...,\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  0.9814,  0.5361,  2.5293],\n",
      "          [ 1.0361,  1.2832, -0.2197,  ...,  1.6152,  0.8984,  1.5244]],\n",
      "\n",
      "         [[-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.5566,  1.2031, -0.2695],\n",
      "          ...,\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.7871,  1.0898, -0.1523],\n",
      "          [-1.1230,  0.1719, -0.8711,  ...,  1.5566,  1.2031, -0.2695]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.4062, -1.8906,  1.4688],\n",
      "          ...,\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.0938, -2.0938,  2.0469],\n",
      "          [ 0.4375, -0.4844,  0.2344,  ..., -1.4062, -1.8906,  1.4688]],\n",
      "\n",
      "         [[-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.0312,  1.3438, -0.4375],\n",
      "          ...,\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.1250,  0.7969, -0.4062],\n",
      "          [-0.8438, -0.3281,  0.8906,  ...,  1.0312,  1.3438, -0.4375]],\n",
      "\n",
      "         [[ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -0.6094,  1.8594, -1.5000],\n",
      "          ...,\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -1.0469,  1.8125, -2.4375],\n",
      "          [ 0.7031,  0.2969,  1.2812,  ..., -0.6094,  1.8594, -1.5000]]]],\n",
      "       device='cuda:0'), tensor(2.8633e+10, device='cuda:0', grad_fn=<AddBackward0>), (None, None, tensor([800, 800, 800,  ..., 585, 585, 585], device='cuda:0')))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor type unknown to einops <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quant, emb_loss, info \u001b[39m=\u001b[39m model1024\u001b[39m.\u001b[39;49mquantize(h)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/g/github/ZSE-SBIR/taming-transformers/taming/modules/vqvae/quantize.py:277\u001b[0m, in \u001b[0;36mVectorQuantizer2.forward\u001b[0;34m(self, z, temp, rescale_logits, return_logits)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m# reshape z -> (batch, height, width, channel) and flatten\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mprint\u001b[39m(z)\n\u001b[0;32m--> 277\u001b[0m z \u001b[39m=\u001b[39m rearrange(z, \u001b[39m'\u001b[39;49m\u001b[39mb c h w -> b h w c\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    278\u001b[0m z_flattened \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39me_dim)\n\u001b[1;32m    279\u001b[0m \u001b[39m# distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/einops/einops.py:483\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRearrange can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be applied to an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    482\u001b[0m     tensor \u001b[39m=\u001b[39m get_backend(tensor[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[0;32m--> 483\u001b[0m \u001b[39mreturn\u001b[39;00m reduce(cast(Tensor, tensor), pattern, reduction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrearrange\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maxes_lengths)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/einops/einops.py:412\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    410\u001b[0m     hashable_axes_lengths \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39msorted\u001b[39m(axes_lengths\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    411\u001b[0m     recipe \u001b[39m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_lengths\u001b[39m=\u001b[39mhashable_axes_lengths)\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m _apply_recipe(recipe, tensor, reduction_type\u001b[39m=\u001b[39;49mreduction)\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m EinopsError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    414\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m Error while processing \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m-reduction pattern \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(reduction, pattern)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/einops/einops.py:233\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply_recipe\u001b[39m(recipe: TransformRecipe, tensor: Tensor, reduction_type: Reduction) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    232\u001b[0m     \u001b[39m# this method works for all backends but not compilable with\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     backend \u001b[39m=\u001b[39m get_backend(tensor)\n\u001b[1;32m    234\u001b[0m     init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes \u001b[39m=\u001b[39m \\\n\u001b[1;32m    235\u001b[0m         _reconstruct_from_shape(recipe, backend\u001b[39m.\u001b[39mshape(tensor))\n\u001b[1;32m    236\u001b[0m     tensor \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/einops/_backends.py:52\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mis_appropriate_type(tensor):\n\u001b[1;32m     50\u001b[0m                 \u001b[39mreturn\u001b[39;00m backend\n\u001b[0;32m---> 52\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTensor type unknown to einops \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(tensor)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor type unknown to einops <class 'tuple'>"
     ]
    }
   ],
   "source": [
    "quant, emb_loss, info = model1024.quantize(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4818a0b8c316263be072c2082609790d2bac6bbfe2378382b84905edb944ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
