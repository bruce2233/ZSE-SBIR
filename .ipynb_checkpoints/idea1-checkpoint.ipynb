{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from options import Option\n",
    "from data_utils.dataset import load_data_test\n",
    "from model.model import Model\n",
    "from utils.util import setup_seed, load_checkpoint\n",
    "import torchvision\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Option().parse()\n",
    "args.load = \"./checkpoint/sketchy_ext/best_checkpoint.pth\"\n",
    "args.batch = 2\n",
    "\n",
    "\n",
    "print(\"test args:\", str(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.ap import calculate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.choose_cuda\n",
    "print(\"current cuda: \" + args.choose_cuda)\n",
    "setup_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "sk_valid_data, im_valid_data = load_data_test(args)\n",
    "\n",
    "# prepare model\n",
    "model = Model(args)\n",
    "model = model.half()\n",
    "\n",
    "if args.load is not None:\n",
    "    checkpoint = load_checkpoint(args.load)\n",
    "\n",
    "cur = model.state_dict()\n",
    "new = {k: v for k, v in checkpoint['model'].items() if k in cur.keys()}\n",
    "cur.update(new)\n",
    "model.load_state_dict(cur)\n",
    "\n",
    "if len(args.choose_cuda) > 1:\n",
    "    model = torch.nn.parallel.DataParallel(model.to('cuda'))\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print('loading image data')\n",
    "sk_dataload = DataLoader(sk_valid_data, batch_size=args.test_sk, num_workers=args.num_workers, drop_last=False)\n",
    "print('loading sketch data')\n",
    "im_dataload = DataLoader(im_valid_data, batch_size=args.test_im, num_workers=args.num_workers, drop_last=False)\n",
    "\n",
    "dist_im = None\n",
    "all_dist = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_valid_data[30][0])\n",
    "torchvision.utils.save_image(sk_valid_data[30][0].cuda(),\"./output/sk-30.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (sk, sk_label) in enumerate(tqdm(sk_dataload)):\n",
    "        #sk.shape=(20,3,224,224)\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            all_sk_label = sk_label.numpy()\n",
    "        else:\n",
    "            all_sk_label = np.concatenate((all_sk_label, sk_label.numpy()), axis=0)\n",
    "\n",
    "        sk_len = sk.size(0)\n",
    "        sk = sk.cuda()\n",
    "        #debug\n",
    "        print(sk.shape, sk[0].shape)\n",
    "        # cv2.imwrite(f\"./output/sk-{i}\",sk[0].cpu().numpy())\n",
    "        if i==0:\n",
    "            grid_sk = torchvision.utils.make_grid(sk)\n",
    "            print(sk)\n",
    "            torchvision.utils.save_image(grid_sk,f\"./output/sk.jpg\")\n",
    "        \n",
    "        sk, sk_idxs = model(sk, None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "        for j, (im, im_label) in enumerate(tqdm(im_dataload)):\n",
    "            if i == 0 and j == 0:\n",
    "                all_im_label = im_label.numpy()\n",
    "            elif i == 0 and j > 0:\n",
    "                all_im_label = np.concatenate((all_im_label, im_label.numpy()), axis=0)\n",
    "\n",
    "            im_len = im.size(0)\n",
    "            im = im.cuda()\n",
    "            im, im_idxs = model(im, None, 'test', only_sa=True)\n",
    "\n",
    "            sk_temp = sk.unsqueeze(1).repeat(1, im_len, 1, 1).flatten(0, 1).cuda() #(400,197,768) #?difference\n",
    "            im_temp = im.unsqueeze(0).repeat(sk_len, 1, 1, 1).flatten(0, 1).cuda() #(400,197,768)\n",
    "            \n",
    "            if args.retrieval == 'rn':\n",
    "                feature_1, feature_2 = model(sk_temp, im_temp, 'test')\n",
    "            #? when retrieval == 'sa'\n",
    "            if args.retrieval == 'sa':\n",
    "                feature_1, feature_2 = torch.cat((sk_temp[:, 0], im_temp[:, 0]), dim=0), None\n",
    "\n",
    "            # print(feature_1.size())    # [2*sk*im, 768] #2 means sk and im cls\n",
    "            # print(feature_2.size())    # [sk*im, 1]\n",
    "\n",
    "            if args.retrieval == 'rn':\n",
    "                if j == 0:\n",
    "                    dist_im = - feature_2.view(sk_len, im_len).cpu().data.numpy()  # 1*args.batch\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, - feature_2.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "            if args.retrieval == 'sa':\n",
    "                dist_temp = F.pairwise_distance(F.normalize(feature_1[:sk_len * im_len]),\n",
    "                                                F.normalize(feature_1[sk_len * im_len:]), 2)\n",
    "                if j == 0:\n",
    "                    dist_im = dist_temp.view(sk_len, im_len).cpu().data.numpy()\n",
    "                else:\n",
    "                    dist_im = np.concatenate((dist_im, dist_temp.view(sk_len, im_len).cpu().data.numpy()), axis=1)\n",
    "\n",
    "        if i == 0:\n",
    "            all_dist = dist_im\n",
    "        else:\n",
    "            all_dist = np.concatenate((all_dist, dist_im), axis=0)\n",
    "        print(all_dist.shape)\n",
    "        #all_dist.shape=(all_sk_label.size, all_im_label.size)\n",
    "    # print(all_sk_label.size, all_im_label.size)     # [762 x 1711] / 2\n",
    "class_same = (np.expand_dims(all_sk_label, axis=1) == np.expand_dims(all_im_label, axis=0)) * 1\n",
    "# print(all_dist.size, class_same.size)     # [762 x 1711] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_dist.shape, class_same.shape)\n",
    "print(all_dist, class_same)\n",
    "np.savetxt(\"./output/all_dist\",all_dist)\n",
    "np.savetxt(\"./output/class_same\",class_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_all, map_200, precision100, precision200 = calculate(all_dist, class_same, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_sort_sim = all_dist.argsort()   # 得到从小到大索引值\n",
    "print(arg_sort_sim.shape)\n",
    "print(arg_sort_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sk,_) = sk_valid_data[0]\n",
    "sk = torch.unsqueeze(sk,0)\n",
    "\n",
    "(im,_) = im_valid_data[30]\n",
    "im = torch.unsqueeze(im,0)\n",
    "\n",
    "im = torch.cat((im,im_valid_data[28][0].unsqueeze(0),im_valid_data[27][0].unsqueeze(0)))\n",
    "\n",
    "print(sk.shape, im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import rn\n",
    "\n",
    "sk_sa, sk_idxs = model(sk.cuda(), None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "im_sa, im_idxs = model(im.cuda(), None, 'test', only_sa=True)#sk.shape=(20,192,768)\n",
    "\n",
    "\n",
    "sk_im_sa = torch.cat((sk_sa, im_sa), dim=0)\n",
    "ca_fea = model.ca(sk_im_sa)  # [2b, 197, 768]\n",
    "cls_fea = ca_fea[:, 0]  # [2b, 1, 768]\n",
    "token_fea = ca_fea[:, 1:]  # [2b, 196, 768]\n",
    "batch = token_fea.size(0)\n",
    "\n",
    "print(token_fea.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_fea = einops.rearrange(token_fea,\"b d h w -> b d (h w)\") #token_fea = token_fea.view(batch, 768, 14, 14)\n",
    "\n",
    "sk_fea = token_fea[sk.size(0)]\n",
    "im_fea = token_fea[sk.size(0)+1:]\n",
    "# np.savetxt(\"./output/sk_fea\", sk_fea.cpu())\n",
    "# np.savetxt(\"./output/im_fea\", im_fea.cpu())\n",
    "print(sk_fea, im_fea)\n",
    "cos_scores = rn.cos_similar(sk_fea, im_fea)\n",
    "print(cos_scores.shape, cos_scores)\n",
    "np.savetxt(\"./output/cos_scores\",cos_scores.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cos_scores.argsort(0).shape,cos_scores.argsort(0))\n",
    "# print(torch.argmax(einops.rearrange(cos_scores,\"a b c -> b (a c)\")))\n",
    "b = einops.rearrange(cos_scores,\"a b c -> b (a c)\")\n",
    "# print(cos_scores.shape,cos_scores)\n",
    "\n",
    "max_indices = torch.empty((0,2), dtype=int)\n",
    "print(b)\n",
    "print(max_indices)\n",
    "\n",
    "for i in b:\n",
    "    max_indices_item = torch.argmax(i)\n",
    "    print(i.shape)\n",
    "    new = np.unravel_index(max_indices_item.cpu(),(cos_scores.shape[0],cos_scores.shape[2]))\n",
    "    # print(torch.Tensor(new))\n",
    "    max_indices = torch.cat((max_indices, torch.tensor(new, dtype=torch.int).unsqueeze(0)), 0)\n",
    "    print(max_indices)\n",
    "    \n",
    "# print(np.unravel_index(b.values, (3, 196)))\n",
    "np.savetxt(\"./output/max_indices\",max_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n",
      "tensor([], size=(0, 3, 224, 224))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m patch_match(im, max_indices)\n",
      "Cell \u001b[0;32mIn[74], line 13\u001b[0m, in \u001b[0;36mpatch_match\u001b[0;34m(im, indices)\u001b[0m\n\u001b[1;32m     11\u001b[0m     patch_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munravel_index(i[\u001b[39m1\u001b[39m],(\u001b[39m16\u001b[39m,\u001b[39m16\u001b[39m))\n\u001b[1;32m     12\u001b[0m     item \u001b[39m=\u001b[39m patch2im(patch_index, im, im\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     x\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(x, item)\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "patch_match(im, max_indices)\n",
    "\n",
    "indices = max_indices\n",
    "print(im.shape)\n",
    "x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "print(x)\n",
    "for i in indices:\n",
    "    selected_im = i[0]\n",
    "    patch_index = np.unravel_index(i[1],(16,16))\n",
    "    item = patch2im(patch_index, im, im.shape[-1]/16)\n",
    "    x= torch.cat(x, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_match(im, indices):\n",
    "    '''\n",
    "        im: (b,c,w,h)\n",
    "        indices: (m,im.shape.len)\n",
    "    '''\n",
    "    print(im.shape)\n",
    "    x = torch.zeros((0,)+tuple(im.shape[1:]))\n",
    "    print(x)\n",
    "    for i in indices:\n",
    "        selected_im = i[0]\n",
    "        patch_index = np.unravel_index(i[1],(16,16))\n",
    "        item = patch2im(patch_index, im, im.shape[-1]/16)\n",
    "        x= torch.cat(x, item)\n",
    "    return x \n",
    "def patch2im(patch_index,im, patch_size):\n",
    "    '''\n",
    "    im: (c, w, h)\n",
    "    patch_index: (2)\n",
    "    '''\n",
    "    width_range = (patch_index[0]*patch_size,(patch_index[0]+1)*patch_size)\n",
    "    height_range = (patch_index[1]*patch_size,(patch_index[1]+1)*patch_size)\n",
    "    return im[:,width_range,height_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # [2b, n, n] n=patches**2\n",
    "cos_scores = cos_scores.view(batch // 2, -1)\n",
    "\n",
    "rn.cos_similar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_dataload[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "# map_all, map_200, precision_100, precision_200 = valid_cls(args, model, sk_valid_data, im_valid_data)\n",
    "print(f'map_all:{map_all:.4f} map_200:{map_200:.4f} precision_100:{precision100:.4f} precision_200:{precision200:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4818a0b8c316263be072c2082609790d2bac6bbfe2378382b84905edb944ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
